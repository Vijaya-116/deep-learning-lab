{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxN26K/Gio/5W65M8FOIyv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vijaya-116/deep-learning-lab/blob/main/with_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using keras implement the matrices multiplicaton"
      ],
      "metadata": {
        "id": "BM3lI8IhQWIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Generate training data\n",
        "def generate_data(num_samples, matrix_size):\n",
        "    X = np.random.randint(0, 10, (num_samples, matrix_size, matrix_size))\n",
        "    Y = np.array([np.dot(x, x) for x in X])\n",
        "    return X, Y\n",
        "\n",
        "# Define the matrix size and number of samples\n",
        "matrix_size = 3\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate data\n",
        "X_train, Y_train = generate_data(num_samples, matrix_size)\n",
        "\n",
        "# Reshape data for the model\n",
        "X_train = X_train.reshape((num_samples, matrix_size, matrix_size, 1))\n",
        "Y_train = Y_train.reshape((num_samples, matrix_size, matrix_size, 1))\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(matrix_size, matrix_size, 1)),\n",
        "    Dense(matrix_size * matrix_size, activation='relu'),\n",
        "    Dense(matrix_size * matrix_size, activation='linear'),\n",
        "    tf.keras.layers.Reshape((matrix_size, matrix_size, 1))\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "X_test, Y_test = generate_data(10, matrix_size)\n",
        "X_test = X_test.reshape((10, matrix_size, matrix_size, 1))\n",
        "Y_test = Y_test.reshape((10, matrix_size, matrix_size, 1))\n",
        "loss = model.evaluate(X_test, Y_test)\n",
        "print(f'Test loss: {loss}')\n",
        "\n",
        "# Test the model with new data\n",
        "X_new = np.random.randint(0, 10, (1, matrix_size, matrix_size))\n",
        "X_new_reshaped = X_new.reshape((1, matrix_size, matrix_size, 1))\n",
        "predictions = model.predict(X_new_reshaped)\n",
        "print(f'Input matrix:\\n{X_new[0]}')\n",
        "print(f'Predicted product:\\n{predictions[0].reshape(matrix_size, matrix_size)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gZulKUqQema",
        "outputId": "35062876-9e30-490a-b1bf-6f21101d2d01"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5433.6050\n",
            "Epoch 2/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5169.6714\n",
            "Epoch 3/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5547.9761\n",
            "Epoch 4/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5497.5620\n",
            "Epoch 5/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5245.0391\n",
            "Epoch 6/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5110.4248\n",
            "Epoch 7/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4836.2012 \n",
            "Epoch 8/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4270.4424\n",
            "Epoch 9/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3778.8452\n",
            "Epoch 10/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3028.2002\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - loss: 2877.8523\n",
            "Test loss: 2877.852294921875\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "Input matrix:\n",
            "[[2 6 7]\n",
            " [1 6 9]\n",
            " [5 7 9]]\n",
            "Predicted product:\n",
            "[[39.014317  33.257652  38.38377  ]\n",
            " [21.794918  25.84046   39.384243 ]\n",
            " [ 8.4663925 19.82277   37.989212 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Keras print prime numbers"
      ],
      "metadata": {
        "id": "qkHUx0u8Q_Wa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def is_prime(n):\n",
        "    if n <= 1:\n",
        "        return False\n",
        "    if n <= 3:\n",
        "        return True\n",
        "    if n % 2 == 0 or n % 3 == 0:\n",
        "        return False\n",
        "    i = 5\n",
        "    while i * i <= n:\n",
        "        if n % i == 0 or n % (i + 2) == 0:\n",
        "            return False\n",
        "        i += 6\n",
        "    return True\n",
        "\n",
        "def generate_prime_data(num_samples):\n",
        "    X = np.arange(num_samples)\n",
        "    Y = np.array([1 if is_prime(x) else 0 for x in X])\n",
        "    return X, Y\n",
        "\n",
        "num_samples = 1000\n",
        "X_train, Y_train = generate_prime_data(num_samples)\n",
        "X_train = X_train.reshape(-1, 1)  # Reshape for the model input\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(64, input_dim=1, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_train, Y_train)\n",
        "print(f'Training accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Predict prime numbers\n",
        "def predict_primes(numbers):\n",
        "    predictions = model.predict(np.array(numbers).reshape(-1, 1))\n",
        "    print(f'Raw predictions: {predictions.flatten()}')  # Debug: print raw predictions\n",
        "    return [num for num, pred in zip(numbers, predictions) if pred > 0.5]\n",
        "\n",
        "# Test with new numbers\n",
        "test_numbers = np.arange(50, 100)\n",
        "primes = predict_primes(test_numbers)\n",
        "print(f'Predicted prime numbers: {primes}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DJc_6-HQ5jC",
        "outputId": "804d8c4a-2e8f-4df5-e9f3-4fa39f0cf64c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7402 - loss: 1.4770 - val_accuracy: 0.8550 - val_loss: 0.7397\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8030 - loss: 0.6481 - val_accuracy: 0.8550 - val_loss: 1.0884\n",
            "Epoch 3/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8305 - loss: 0.5960 - val_accuracy: 0.8550 - val_loss: 1.0817\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8442 - loss: 0.4833 - val_accuracy: 0.8550 - val_loss: 0.4954\n",
            "Epoch 5/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8266 - loss: 0.4972 - val_accuracy: 0.8550 - val_loss: 0.5421\n",
            "Epoch 6/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8371 - loss: 0.5271 - val_accuracy: 0.8550 - val_loss: 0.4850\n",
            "Epoch 7/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.4583 - val_accuracy: 0.8550 - val_loss: 0.4501\n",
            "Epoch 8/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8280 - loss: 0.5304 - val_accuracy: 0.8550 - val_loss: 0.4448\n",
            "Epoch 9/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8181 - loss: 0.5126 - val_accuracy: 0.8550 - val_loss: 0.5156\n",
            "Epoch 10/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8273 - loss: 0.5139 - val_accuracy: 0.8550 - val_loss: 0.4842\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8014 - loss: 0.5162 \n",
            "Training accuracy: 0.8320\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Raw predictions: [0.38360864 0.38290125 0.38219425 0.38148782 0.38078177 0.38007614\n",
            " 0.37937135 0.37866682 0.37796277 0.37725914 0.37655628 0.375854\n",
            " 0.37515187 0.37445033 0.37374973 0.37304926 0.37234932 0.37165025\n",
            " 0.37095234 0.37025747 0.36956316 0.36886963 0.36817628 0.3674839\n",
            " 0.3667915  0.36610022 0.36540923 0.36471853 0.3640289  0.36333945\n",
            " 0.36265063 0.36196256 0.36127475 0.3605874  0.3599011  0.35921505\n",
            " 0.35852975 0.35784528 0.35716057 0.35647714 0.35579422 0.35511163\n",
            " 0.35442987 0.3537484  0.35306776 0.35238743 0.35170814 0.3510293\n",
            " 0.3503509  0.34967288]\n",
            "Predicted prime numbers: []\n"
          ]
        }
      ]
    }
  ]
}